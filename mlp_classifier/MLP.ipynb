{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srimaailuri/Machine_learning/blob/master/mlp_classifier/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "9sfxj7KIenKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb70295-71ec-4a30-b889-cdcfdda2cc73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/My Drive/srima_DL_Lab/week 2'"
      ],
      "metadata": {
        "id": "LAbSojCDeoB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c294064a-be08-40c3-b70d-16ff02955dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/srima_DL_Lab/week 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8YU1WQMdV8W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a0c7971a-927e-477b-d928-b74735ab898c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
              "0   1            5.1           3.5            1.4           0.2        0\n",
              "1   2            4.9           3.0            1.4           0.2        0\n",
              "2   3            4.7           3.2            1.3           0.2        0\n",
              "3   4            4.6           3.1            1.5           0.2        0\n",
              "4   5            5.0           3.6            1.4           0.2        0"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-d60e9634-422f-4d2f-acc4-2e2d7c0177c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d60e9634-422f-4d2f-acc4-2e2d7c0177c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-52bc7e3d-b5d5-4375-9696-1da8f04368dd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52bc7e3d-b5d5-4375-9696-1da8f04368dd')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-52bc7e3d-b5d5-4375-9696-1da8f04368dd button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d60e9634-422f-4d2f-acc4-2e2d7c0177c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d60e9634-422f-4d2f-acc4-2e2d7c0177c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load data\n",
        "data=pd.read_csv('Iris-new (2).csv')\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HbUzuFjtN8j",
        "outputId": "bdb15831-301b-4160-d5ab-a843d5706487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm',\n",
              "       'Species'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=data.iloc[:,1:5]"
      ],
      "metadata": {
        "id": "-OH1LbhC8a-K"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "_VafM6YF8j-K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "62396dda-f73f-4201-cd67-8efda5e4e6d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
              "0            5.1           3.5            1.4           0.2\n",
              "1            4.9           3.0            1.4           0.2\n",
              "2            4.7           3.2            1.3           0.2\n",
              "3            4.6           3.1            1.5           0.2\n",
              "4            5.0           3.6            1.4           0.2"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-5c1d39b6-4e87-4af7-9d6e-4820cb862504\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c1d39b6-4e87-4af7-9d6e-4820cb862504')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-dd83cb6d-cace-4a17-a621-48c48b8f73a9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd83cb6d-cace-4a17-a621-48c48b8f73a9')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-dd83cb6d-cace-4a17-a621-48c48b8f73a9 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c1d39b6-4e87-4af7-9d6e-4820cb862504 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c1d39b6-4e87-4af7-9d6e-4820cb862504');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X=data[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\n",
        "y=data.iloc[:,-1]"
      ],
      "metadata": {
        "id": "2jvJo0qisfUi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QzGC7uYotrNC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l3CYJEnndX8e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting data into Feature and\n",
        "#X=data[['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'time_spend_company', 'Work_accident', 'promotion_last_5years', 'Departments ', 'salary']]\n",
        "#y=data['left']\n",
        "\n",
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)  # 70% training and 30% test"
      ],
      "metadata": {
        "id": "8bwjmD1fdaol"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import MLPClassifer\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "Ihf8kks_df0t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Applying Adam classifier***"
      ],
      "metadata": {
        "id": "w0NPxcuc96zC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(6,5),\n",
        "                    solver='adam',\n",
        "                    random_state=5,\n",
        "                    verbose=True,\n",
        "                    learning_rate_init=0.01)\n",
        "\n",
        "# Fit data onto the model\n",
        "clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TQ6v6VqT9ug-",
        "outputId": "d251924d-9ac6-4843-dcce-c73c15afec2c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.35506854\n",
            "Iteration 2, loss = 1.27999888\n",
            "Iteration 3, loss = 1.21041075\n",
            "Iteration 4, loss = 1.14576532\n",
            "Iteration 5, loss = 1.08972046\n",
            "Iteration 6, loss = 1.04920622\n",
            "Iteration 7, loss = 1.01442134\n",
            "Iteration 8, loss = 0.98321630\n",
            "Iteration 9, loss = 0.95568467\n",
            "Iteration 10, loss = 0.93079136\n",
            "Iteration 11, loss = 0.90811747\n",
            "Iteration 12, loss = 0.88759212\n",
            "Iteration 13, loss = 0.86841651\n",
            "Iteration 14, loss = 0.85021572\n",
            "Iteration 15, loss = 0.83232394\n",
            "Iteration 16, loss = 0.81370119\n",
            "Iteration 17, loss = 0.79289950\n",
            "Iteration 18, loss = 0.76952148\n",
            "Iteration 19, loss = 0.74468198\n",
            "Iteration 20, loss = 0.71948005\n",
            "Iteration 21, loss = 0.69437466\n",
            "Iteration 22, loss = 0.66937842\n",
            "Iteration 23, loss = 0.64514851\n",
            "Iteration 24, loss = 0.62227408\n",
            "Iteration 25, loss = 0.60009846\n",
            "Iteration 26, loss = 0.57787614\n",
            "Iteration 27, loss = 0.55491283\n",
            "Iteration 28, loss = 0.53178016\n",
            "Iteration 29, loss = 0.50899778\n",
            "Iteration 30, loss = 0.48681362\n",
            "Iteration 31, loss = 0.46523811\n",
            "Iteration 32, loss = 0.44491639\n",
            "Iteration 33, loss = 0.42587590\n",
            "Iteration 34, loss = 0.40786336\n",
            "Iteration 35, loss = 0.39035023\n",
            "Iteration 36, loss = 0.37326600\n",
            "Iteration 37, loss = 0.35685861\n",
            "Iteration 38, loss = 0.34128649\n",
            "Iteration 39, loss = 0.32684774\n",
            "Iteration 40, loss = 0.31341361\n",
            "Iteration 41, loss = 0.30076140\n",
            "Iteration 42, loss = 0.28910267\n",
            "Iteration 43, loss = 0.27806570\n",
            "Iteration 44, loss = 0.26745105\n",
            "Iteration 45, loss = 0.25729847\n",
            "Iteration 46, loss = 0.24755956\n",
            "Iteration 47, loss = 0.23773154\n",
            "Iteration 48, loss = 0.22842472\n",
            "Iteration 49, loss = 0.21988570\n",
            "Iteration 50, loss = 0.21155778\n",
            "Iteration 51, loss = 0.20360147\n",
            "Iteration 52, loss = 0.19625436\n",
            "Iteration 53, loss = 0.18908542\n",
            "Iteration 54, loss = 0.18219511\n",
            "Iteration 55, loss = 0.17580220\n",
            "Iteration 56, loss = 0.16959217\n",
            "Iteration 57, loss = 0.16371307\n",
            "Iteration 58, loss = 0.15827058\n",
            "Iteration 59, loss = 0.15300608\n",
            "Iteration 60, loss = 0.14810965\n",
            "Iteration 61, loss = 0.14352093\n",
            "Iteration 62, loss = 0.13908360\n",
            "Iteration 63, loss = 0.13498760\n",
            "Iteration 64, loss = 0.13105922\n",
            "Iteration 65, loss = 0.12734932\n",
            "Iteration 66, loss = 0.12395210\n",
            "Iteration 67, loss = 0.12071929\n",
            "Iteration 68, loss = 0.11780031\n",
            "Iteration 69, loss = 0.11499259\n",
            "Iteration 70, loss = 0.11241261\n",
            "Iteration 71, loss = 0.10994981\n",
            "Iteration 72, loss = 0.10761912\n",
            "Iteration 73, loss = 0.10543820\n",
            "Iteration 74, loss = 0.10336352\n",
            "Iteration 75, loss = 0.10142789\n",
            "Iteration 76, loss = 0.09957319\n",
            "Iteration 77, loss = 0.09785620\n",
            "Iteration 78, loss = 0.09619069\n",
            "Iteration 79, loss = 0.09463892\n",
            "Iteration 80, loss = 0.09313340\n",
            "Iteration 81, loss = 0.09171704\n",
            "Iteration 82, loss = 0.09035228\n",
            "Iteration 83, loss = 0.08905310\n",
            "Iteration 84, loss = 0.08780999\n",
            "Iteration 85, loss = 0.08661539\n",
            "Iteration 86, loss = 0.08548438\n",
            "Iteration 87, loss = 0.08438231\n",
            "Iteration 88, loss = 0.08334720\n",
            "Iteration 89, loss = 0.08234027\n",
            "Iteration 90, loss = 0.08139349\n",
            "Iteration 91, loss = 0.08047360\n",
            "Iteration 92, loss = 0.07959561\n",
            "Iteration 93, loss = 0.07875877\n",
            "Iteration 94, loss = 0.07794671\n",
            "Iteration 95, loss = 0.07717852\n",
            "Iteration 96, loss = 0.07643449\n",
            "Iteration 97, loss = 0.07572175\n",
            "Iteration 98, loss = 0.07504126\n",
            "Iteration 99, loss = 0.07438147\n",
            "Iteration 100, loss = 0.07375285\n",
            "Iteration 101, loss = 0.07314918\n",
            "Iteration 102, loss = 0.07256640\n",
            "Iteration 103, loss = 0.07201108\n",
            "Iteration 104, loss = 0.07147786\n",
            "Iteration 105, loss = 0.07096384\n",
            "Iteration 106, loss = 0.07047334\n",
            "Iteration 107, loss = 0.07000382\n",
            "Iteration 108, loss = 0.06955138\n",
            "Iteration 109, loss = 0.06911771\n",
            "Iteration 110, loss = 0.06870360\n",
            "Iteration 111, loss = 0.06830594\n",
            "Iteration 112, loss = 0.06792311\n",
            "Iteration 113, loss = 0.06755650\n",
            "Iteration 114, loss = 0.06720603\n",
            "Iteration 115, loss = 0.06686983\n",
            "Iteration 116, loss = 0.06655007\n",
            "Iteration 117, loss = 0.06624291\n",
            "Iteration 118, loss = 0.06594805\n",
            "Iteration 119, loss = 0.06566507\n",
            "Iteration 120, loss = 0.06539339\n",
            "Iteration 121, loss = 0.06513230\n",
            "Iteration 122, loss = 0.06488110\n",
            "Iteration 123, loss = 0.06463951\n",
            "Iteration 124, loss = 0.06440701\n",
            "Iteration 125, loss = 0.06418380\n",
            "Iteration 126, loss = 0.06396952\n",
            "Iteration 127, loss = 0.06376456\n",
            "Iteration 128, loss = 0.06356975\n",
            "Iteration 129, loss = 0.06338811\n",
            "Iteration 130, loss = 0.06322144\n",
            "Iteration 131, loss = 0.06306879\n",
            "Iteration 132, loss = 0.06291344\n",
            "Iteration 133, loss = 0.06272718\n",
            "Iteration 134, loss = 0.06252502\n",
            "Iteration 135, loss = 0.06235913\n",
            "Iteration 136, loss = 0.06223492\n",
            "Iteration 137, loss = 0.06211153\n",
            "Iteration 138, loss = 0.06195804\n",
            "Iteration 139, loss = 0.06179684\n",
            "Iteration 140, loss = 0.06166441\n",
            "Iteration 141, loss = 0.06155572\n",
            "Iteration 142, loss = 0.06143925\n",
            "Iteration 143, loss = 0.06130352\n",
            "Iteration 144, loss = 0.06117108\n",
            "Iteration 145, loss = 0.06105993\n",
            "Iteration 146, loss = 0.06096061\n",
            "Iteration 147, loss = 0.06085470\n",
            "Iteration 148, loss = 0.06073824\n",
            "Iteration 149, loss = 0.06062533\n",
            "Iteration 150, loss = 0.06052385\n",
            "Iteration 151, loss = 0.06043091\n",
            "Iteration 152, loss = 0.06034065\n",
            "Iteration 153, loss = 0.06024621\n",
            "Iteration 154, loss = 0.06014742\n",
            "Iteration 155, loss = 0.06004902\n",
            "Iteration 156, loss = 0.05995695\n",
            "Iteration 157, loss = 0.05987203\n",
            "Iteration 158, loss = 0.05979125\n",
            "Iteration 159, loss = 0.05971122\n",
            "Iteration 160, loss = 0.05962978\n",
            "Iteration 161, loss = 0.05954698\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(6, 5), learning_rate_init=0.01,\n",
              "              random_state=5, verbose=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(6, 5), learning_rate_init=0.01,\n",
              "              random_state=5, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(6, 5), learning_rate_init=0.01,\n",
              "              random_state=5, verbose=True)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction on test dataset\n",
        "ypred=clf.predict(X_test)\n",
        "\n",
        "# Import accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calcuate accuracy\n",
        "accuracy_score(y_test,ypred)"
      ],
      "metadata": {
        "id": "NQUqAgLRdlN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c059e2e9-407f-4043-ef20-396115c67a6e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "OV19rJY6t5pq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm=confusion_matrix(y_test,ypred)"
      ],
      "metadata": {
        "id": "C2YKKaTht5tb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(cm,annot=True,fmt='g')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ttR9uWY5usKK",
        "outputId": "15f3fc31-2b86-4270-9e26-50bcbafb4603"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***LBFGS***"
      ],
      "metadata": {
        "id": "3Et5AIHN-sxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(6,5),\n",
        "                    solver='lbfgs',\n",
        "                    random_state=5,\n",
        "                    verbose=True,\n",
        "                    learning_rate_init=0.01)\n",
        "\n",
        "# Fit data onto the model\n",
        "clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "yR6Ow2OY-ruD",
        "outputId": "9be4db39-fc97-42aa-d3bc-122772b8e9b3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(6, 5), learning_rate_init=0.01,\n",
              "              random_state=5, solver='lbfgs', verbose=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(6, 5), learning_rate_init=0.01,\n",
              "              random_state=5, solver=&#x27;lbfgs&#x27;, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(6, 5), learning_rate_init=0.01,\n",
              "              random_state=5, solver=&#x27;lbfgs&#x27;, verbose=True)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction on test dataset\n",
        "ypred=clf.predict(X_test)\n",
        "\n",
        "# Import accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calcuate accuracy\n",
        "accuracy_score(y_test,ypred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCecmYJg-rwr",
        "outputId": "c25484e7-4663-4b04-913d-cd1d8ec0796e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***SGD***"
      ],
      "metadata": {
        "id": "lKXEzy3k_P-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(6,5),\n",
        "                    solver='sgd',\n",
        "                    random_state=5,\n",
        "                    verbose=True,\n",
        "                    learning_rate_init=0.01)\n",
        "\n",
        "# Fit data onto the model\n",
        "clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hOUHwcUe-r0Z",
        "outputId": "c6ff5b6d-90d1-42f0-b88e-61f6757d333c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.35506854\n",
            "Iteration 2, loss = 1.32175954\n",
            "Iteration 3, loss = 1.28014103\n",
            "Iteration 4, loss = 1.23288493\n",
            "Iteration 5, loss = 1.18171570\n",
            "Iteration 6, loss = 1.13024273\n",
            "Iteration 7, loss = 1.09442391\n",
            "Iteration 8, loss = 1.06406050\n",
            "Iteration 9, loss = 1.03174820\n",
            "Iteration 10, loss = 0.99847893\n",
            "Iteration 11, loss = 0.96542915\n",
            "Iteration 12, loss = 0.93402440\n",
            "Iteration 13, loss = 0.90574225\n",
            "Iteration 14, loss = 0.88190410\n",
            "Iteration 15, loss = 0.86053642\n",
            "Iteration 16, loss = 0.84086628\n",
            "Iteration 17, loss = 0.82116353\n",
            "Iteration 18, loss = 0.79961870\n",
            "Iteration 19, loss = 0.77560950\n",
            "Iteration 20, loss = 0.74915414\n",
            "Iteration 21, loss = 0.72074156\n",
            "Iteration 22, loss = 0.69082168\n",
            "Iteration 23, loss = 0.66027214\n",
            "Iteration 24, loss = 0.62984633\n",
            "Iteration 25, loss = 0.60010189\n",
            "Iteration 26, loss = 0.57115884\n",
            "Iteration 27, loss = 0.54299369\n",
            "Iteration 28, loss = 0.51549613\n",
            "Iteration 29, loss = 0.48878348\n",
            "Iteration 30, loss = 0.46315430\n",
            "Iteration 31, loss = 0.43889200\n",
            "Iteration 32, loss = 0.41643477\n",
            "Iteration 33, loss = 0.39593148\n",
            "Iteration 34, loss = 0.37723193\n",
            "Iteration 35, loss = 0.36012574\n",
            "Iteration 36, loss = 0.34438554\n",
            "Iteration 37, loss = 0.32977356\n",
            "Iteration 38, loss = 0.31621201\n",
            "Iteration 39, loss = 0.30358893\n",
            "Iteration 40, loss = 0.29197857\n",
            "Iteration 41, loss = 0.28115368\n",
            "Iteration 42, loss = 0.27109698\n",
            "Iteration 43, loss = 0.26167273\n",
            "Iteration 44, loss = 0.25280462\n",
            "Iteration 45, loss = 0.24446558\n",
            "Iteration 46, loss = 0.23657387\n",
            "Iteration 47, loss = 0.22912963\n",
            "Iteration 48, loss = 0.22205979\n",
            "Iteration 49, loss = 0.21539608\n",
            "Iteration 50, loss = 0.20907961\n",
            "Iteration 51, loss = 0.20308054\n",
            "Iteration 52, loss = 0.19737483\n",
            "Iteration 53, loss = 0.19194520\n",
            "Iteration 54, loss = 0.18678182\n",
            "Iteration 55, loss = 0.18187276\n",
            "Iteration 56, loss = 0.17720601\n",
            "Iteration 57, loss = 0.17277042\n",
            "Iteration 58, loss = 0.16855552\n",
            "Iteration 59, loss = 0.16455149\n",
            "Iteration 60, loss = 0.16074906\n",
            "Iteration 61, loss = 0.15713935\n",
            "Iteration 62, loss = 0.15371377\n",
            "Iteration 63, loss = 0.15046395\n",
            "Iteration 64, loss = 0.14738412\n",
            "Iteration 65, loss = 0.14446444\n",
            "Iteration 66, loss = 0.14169680\n",
            "Iteration 67, loss = 0.13907268\n",
            "Iteration 68, loss = 0.13658456\n",
            "Iteration 69, loss = 0.13422488\n",
            "Iteration 70, loss = 0.13198760\n",
            "Iteration 71, loss = 0.12986486\n",
            "Iteration 72, loss = 0.12784992\n",
            "Iteration 73, loss = 0.12593646\n",
            "Iteration 74, loss = 0.12411901\n",
            "Iteration 75, loss = 0.12239211\n",
            "Iteration 76, loss = 0.12074972\n",
            "Iteration 77, loss = 0.11918670\n",
            "Iteration 78, loss = 0.11769901\n",
            "Iteration 79, loss = 0.11628219\n",
            "Iteration 80, loss = 0.11493148\n",
            "Iteration 81, loss = 0.11364279\n",
            "Iteration 82, loss = 0.11241249\n",
            "Iteration 83, loss = 0.11123708\n",
            "Iteration 84, loss = 0.11011336\n",
            "Iteration 85, loss = 0.10903829\n",
            "Iteration 86, loss = 0.10800905\n",
            "Iteration 87, loss = 0.10702300\n",
            "Iteration 88, loss = 0.10607766\n",
            "Iteration 89, loss = 0.10517071\n",
            "Iteration 90, loss = 0.10430073\n",
            "Iteration 91, loss = 0.10346480\n",
            "Iteration 92, loss = 0.10266102\n",
            "Iteration 93, loss = 0.10188762\n",
            "Iteration 94, loss = 0.10114296\n",
            "Iteration 95, loss = 0.10042551\n",
            "Iteration 96, loss = 0.09973386\n",
            "Iteration 97, loss = 0.09906710\n",
            "Iteration 98, loss = 0.09842362\n",
            "Iteration 99, loss = 0.09780221\n",
            "Iteration 100, loss = 0.09720175\n",
            "Iteration 101, loss = 0.09662121\n",
            "Iteration 102, loss = 0.09605960\n",
            "Iteration 103, loss = 0.09551601\n",
            "Iteration 104, loss = 0.09498959\n",
            "Iteration 105, loss = 0.09447954\n",
            "Iteration 106, loss = 0.09398508\n",
            "Iteration 107, loss = 0.09350553\n",
            "Iteration 108, loss = 0.09304034\n",
            "Iteration 109, loss = 0.09258862\n",
            "Iteration 110, loss = 0.09214996\n",
            "Iteration 111, loss = 0.09172365\n",
            "Iteration 112, loss = 0.09130926\n",
            "Iteration 113, loss = 0.09090631\n",
            "Iteration 114, loss = 0.09051431\n",
            "Iteration 115, loss = 0.09013290\n",
            "Iteration 116, loss = 0.08976138\n",
            "Iteration 117, loss = 0.08939960\n",
            "Iteration 118, loss = 0.08904711\n",
            "Iteration 119, loss = 0.08870356\n",
            "Iteration 120, loss = 0.08836859\n",
            "Iteration 121, loss = 0.08804190\n",
            "Iteration 122, loss = 0.08772321\n",
            "Iteration 123, loss = 0.08741222\n",
            "Iteration 124, loss = 0.08710851\n",
            "Iteration 125, loss = 0.08681201\n",
            "Iteration 126, loss = 0.08652238\n",
            "Iteration 127, loss = 0.08623941\n",
            "Iteration 128, loss = 0.08596285\n",
            "Iteration 129, loss = 0.08569251\n",
            "Iteration 130, loss = 0.08542823\n",
            "Iteration 131, loss = 0.08516963\n",
            "Iteration 132, loss = 0.08491670\n",
            "Iteration 133, loss = 0.08466919\n",
            "Iteration 134, loss = 0.08442695\n",
            "Iteration 135, loss = 0.08418981\n",
            "Iteration 136, loss = 0.08395763\n",
            "Iteration 137, loss = 0.08373036\n",
            "Iteration 138, loss = 0.08350775\n",
            "Iteration 139, loss = 0.08328964\n",
            "Iteration 140, loss = 0.08307591\n",
            "Iteration 141, loss = 0.08286643\n",
            "Iteration 142, loss = 0.08266106\n",
            "Iteration 143, loss = 0.08245970\n",
            "Iteration 144, loss = 0.08226222\n",
            "Iteration 145, loss = 0.08206851\n",
            "Iteration 146, loss = 0.08187848\n",
            "Iteration 147, loss = 0.08169202\n",
            "Iteration 148, loss = 0.08150903\n",
            "Iteration 149, loss = 0.08132942\n",
            "Iteration 150, loss = 0.08115309\n",
            "Iteration 151, loss = 0.08097996\n",
            "Iteration 152, loss = 0.08080995\n",
            "Iteration 153, loss = 0.08064298\n",
            "Iteration 154, loss = 0.08047896\n",
            "Iteration 155, loss = 0.08031782\n",
            "Iteration 156, loss = 0.08015949\n",
            "Iteration 157, loss = 0.08000389\n",
            "Iteration 158, loss = 0.07985096\n",
            "Iteration 159, loss = 0.07970064\n",
            "Iteration 160, loss = 0.07955285\n",
            "Iteration 161, loss = 0.07940754\n",
            "Iteration 162, loss = 0.07926465\n",
            "Iteration 163, loss = 0.07912411\n",
            "Iteration 164, loss = 0.07898588\n",
            "Iteration 165, loss = 0.07884990\n",
            "Iteration 166, loss = 0.07871611\n",
            "Iteration 167, loss = 0.07858446\n",
            "Iteration 168, loss = 0.07845491\n",
            "Iteration 169, loss = 0.07832741\n",
            "Iteration 170, loss = 0.07820191\n",
            "Iteration 171, loss = 0.07807836\n",
            "Iteration 172, loss = 0.07795673\n",
            "Iteration 173, loss = 0.07783696\n",
            "Iteration 174, loss = 0.07771902\n",
            "Iteration 175, loss = 0.07760286\n",
            "Iteration 176, loss = 0.07748846\n",
            "Iteration 177, loss = 0.07737576\n",
            "Iteration 178, loss = 0.07726474\n",
            "Iteration 179, loss = 0.07715535\n",
            "Iteration 180, loss = 0.07704756\n",
            "Iteration 181, loss = 0.07694134\n",
            "Iteration 182, loss = 0.07683666\n",
            "Iteration 183, loss = 0.07673348\n",
            "Iteration 184, loss = 0.07663177\n",
            "Iteration 185, loss = 0.07653150\n",
            "Iteration 186, loss = 0.07643264\n",
            "Iteration 187, loss = 0.07633516\n",
            "Iteration 188, loss = 0.07623903\n",
            "Iteration 189, loss = 0.07614423\n",
            "Iteration 190, loss = 0.07605073\n",
            "Iteration 191, loss = 0.07595851\n",
            "Iteration 192, loss = 0.07586753\n",
            "Iteration 193, loss = 0.07577777\n",
            "Iteration 194, loss = 0.07568921\n",
            "Iteration 195, loss = 0.07560182\n",
            "Iteration 196, loss = 0.07551559\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(6, 5), learning_rate_init=0.01,\n",
              "              random_state=5, solver='sgd', verbose=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(6, 5), learning_rate_init=0.01,\n",
              "              random_state=5, solver=&#x27;sgd&#x27;, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(6, 5), learning_rate_init=0.01,\n",
              "              random_state=5, solver=&#x27;sgd&#x27;, verbose=True)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction on test dataset\n",
        "ypred=clf.predict(X_test)\n",
        "\n",
        "# Import accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calcuate accuracy\n",
        "accuracy_score(y_test,ypred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76ZrLVHh-r2M",
        "outputId": "df1dbc4a-e9b5-4238-e28b-de04774cdff9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(6,5),\n",
        "                    solver='sgd',\n",
        "                    activation='tanh',\n",
        "                    random_state=5,\n",
        "                    verbose=True,\n",
        "                    learning_rate_init=0.01)\n",
        "\n",
        "# Fit data onto the model\n",
        "clf.fit(X_train,y_train)\n",
        "# Make prediction on test dataset\n",
        "ypred=clf.predict(X_test)\n",
        "\n",
        "# Import accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calcuate accuracy\n",
        "accuracy_score(y_test,ypred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqbMtHdM-r6s",
        "outputId": "e9f3b125-f007-47f4-c770-2bb01d83ae1f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.16913845\n",
            "Iteration 2, loss = 1.15687429\n",
            "Iteration 3, loss = 1.13932047\n",
            "Iteration 4, loss = 1.11684776\n",
            "Iteration 5, loss = 1.08992681\n",
            "Iteration 6, loss = 1.05973058\n",
            "Iteration 7, loss = 1.02855115\n",
            "Iteration 8, loss = 0.99868111\n",
            "Iteration 9, loss = 0.97072882\n",
            "Iteration 10, loss = 0.94468577\n",
            "Iteration 11, loss = 0.92146962\n",
            "Iteration 12, loss = 0.90167821\n",
            "Iteration 13, loss = 0.88457039\n",
            "Iteration 14, loss = 0.86914806\n",
            "Iteration 15, loss = 0.85493911\n",
            "Iteration 16, loss = 0.84168411\n",
            "Iteration 17, loss = 0.82901413\n",
            "Iteration 18, loss = 0.81650086\n",
            "Iteration 19, loss = 0.80378816\n",
            "Iteration 20, loss = 0.79063043\n",
            "Iteration 21, loss = 0.77689242\n",
            "Iteration 22, loss = 0.76257917\n",
            "Iteration 23, loss = 0.74786468\n",
            "Iteration 24, loss = 0.73305009\n",
            "Iteration 25, loss = 0.71846037\n",
            "Iteration 26, loss = 0.70435020\n",
            "Iteration 27, loss = 0.69085367\n",
            "Iteration 28, loss = 0.67797841\n",
            "Iteration 29, loss = 0.66564179\n",
            "Iteration 30, loss = 0.65372565\n",
            "Iteration 31, loss = 0.64211561\n",
            "Iteration 32, loss = 0.63071502\n",
            "Iteration 33, loss = 0.61944666\n",
            "Iteration 34, loss = 0.60825357\n",
            "Iteration 35, loss = 0.59709957\n",
            "Iteration 36, loss = 0.58596740\n",
            "Iteration 37, loss = 0.57485473\n",
            "Iteration 38, loss = 0.56376982\n",
            "Iteration 39, loss = 0.55272783\n",
            "Iteration 40, loss = 0.54174842\n",
            "Iteration 41, loss = 0.53085455\n",
            "Iteration 42, loss = 0.52007261\n",
            "Iteration 43, loss = 0.50943364\n",
            "Iteration 44, loss = 0.49897513\n",
            "Iteration 45, loss = 0.48874230\n",
            "Iteration 46, loss = 0.47878734\n",
            "Iteration 47, loss = 0.46916498\n",
            "Iteration 48, loss = 0.45992392\n",
            "Iteration 49, loss = 0.45109577\n",
            "Iteration 50, loss = 0.44268550\n",
            "Iteration 51, loss = 0.43466836\n",
            "Iteration 52, loss = 0.42699552\n",
            "Iteration 53, loss = 0.41960644\n",
            "Iteration 54, loss = 0.41244263\n",
            "Iteration 55, loss = 0.40545730\n",
            "Iteration 56, loss = 0.39861883\n",
            "Iteration 57, loss = 0.39190909\n",
            "Iteration 58, loss = 0.38531945\n",
            "Iteration 59, loss = 0.37884721\n",
            "Iteration 60, loss = 0.37249330\n",
            "Iteration 61, loss = 0.36626124\n",
            "Iteration 62, loss = 0.36015660\n",
            "Iteration 63, loss = 0.35418636\n",
            "Iteration 64, loss = 0.34835800\n",
            "Iteration 65, loss = 0.34267824\n",
            "Iteration 66, loss = 0.33715201\n",
            "Iteration 67, loss = 0.33178162\n",
            "Iteration 68, loss = 0.32656647\n",
            "Iteration 69, loss = 0.32150329\n",
            "Iteration 70, loss = 0.31658668\n",
            "Iteration 71, loss = 0.31180992\n",
            "Iteration 72, loss = 0.30716570\n",
            "Iteration 73, loss = 0.30264684\n",
            "Iteration 74, loss = 0.29824669\n",
            "Iteration 75, loss = 0.29395942\n",
            "Iteration 76, loss = 0.28978006\n",
            "Iteration 77, loss = 0.28570448\n",
            "Iteration 78, loss = 0.28172920\n",
            "Iteration 79, loss = 0.27785129\n",
            "Iteration 80, loss = 0.27406818\n",
            "Iteration 81, loss = 0.27037752\n",
            "Iteration 82, loss = 0.26677714\n",
            "Iteration 83, loss = 0.26326494\n",
            "Iteration 84, loss = 0.25983883\n",
            "Iteration 85, loss = 0.25649679\n",
            "Iteration 86, loss = 0.25323675\n",
            "Iteration 87, loss = 0.25005666\n",
            "Iteration 88, loss = 0.24695447\n",
            "Iteration 89, loss = 0.24392810\n",
            "Iteration 90, loss = 0.24097548\n",
            "Iteration 91, loss = 0.23809454\n",
            "Iteration 92, loss = 0.23528321\n",
            "Iteration 93, loss = 0.23253944\n",
            "Iteration 94, loss = 0.22986120\n",
            "Iteration 95, loss = 0.22724652\n",
            "Iteration 96, loss = 0.22469345\n",
            "Iteration 97, loss = 0.22220012\n",
            "Iteration 98, loss = 0.21976472\n",
            "Iteration 99, loss = 0.21738548\n",
            "Iteration 100, loss = 0.21506072\n",
            "Iteration 101, loss = 0.21278884\n",
            "Iteration 102, loss = 0.21056827\n",
            "Iteration 103, loss = 0.20839754\n",
            "Iteration 104, loss = 0.20627520\n",
            "Iteration 105, loss = 0.20419988\n",
            "Iteration 106, loss = 0.20217024\n",
            "Iteration 107, loss = 0.20018500\n",
            "Iteration 108, loss = 0.19824291\n",
            "Iteration 109, loss = 0.19634274\n",
            "Iteration 110, loss = 0.19448333\n",
            "Iteration 111, loss = 0.19266353\n",
            "Iteration 112, loss = 0.19088223\n",
            "Iteration 113, loss = 0.18913835\n",
            "Iteration 114, loss = 0.18743084\n",
            "Iteration 115, loss = 0.18575869\n",
            "Iteration 116, loss = 0.18412090\n",
            "Iteration 117, loss = 0.18251653\n",
            "Iteration 118, loss = 0.18094464\n",
            "Iteration 119, loss = 0.17940436\n",
            "Iteration 120, loss = 0.17789481\n",
            "Iteration 121, loss = 0.17641517\n",
            "Iteration 122, loss = 0.17496462\n",
            "Iteration 123, loss = 0.17354238\n",
            "Iteration 124, loss = 0.17214772\n",
            "Iteration 125, loss = 0.17077990\n",
            "Iteration 126, loss = 0.16943821\n",
            "Iteration 127, loss = 0.16812199\n",
            "Iteration 128, loss = 0.16683058\n",
            "Iteration 129, loss = 0.16556335\n",
            "Iteration 130, loss = 0.16431968\n",
            "Iteration 131, loss = 0.16309898\n",
            "Iteration 132, loss = 0.16190067\n",
            "Iteration 133, loss = 0.16072421\n",
            "Iteration 134, loss = 0.15956906\n",
            "Iteration 135, loss = 0.15843469\n",
            "Iteration 136, loss = 0.15732061\n",
            "Iteration 137, loss = 0.15622632\n",
            "Iteration 138, loss = 0.15515135\n",
            "Iteration 139, loss = 0.15409524\n",
            "Iteration 140, loss = 0.15305756\n",
            "Iteration 141, loss = 0.15203786\n",
            "Iteration 142, loss = 0.15103574\n",
            "Iteration 143, loss = 0.15005080\n",
            "Iteration 144, loss = 0.14908263\n",
            "Iteration 145, loss = 0.14813086\n",
            "Iteration 146, loss = 0.14719512\n",
            "Iteration 147, loss = 0.14627505\n",
            "Iteration 148, loss = 0.14537031\n",
            "Iteration 149, loss = 0.14448057\n",
            "Iteration 150, loss = 0.14360549\n",
            "Iteration 151, loss = 0.14274476\n",
            "Iteration 152, loss = 0.14189806\n",
            "Iteration 153, loss = 0.14106511\n",
            "Iteration 154, loss = 0.14024561\n",
            "Iteration 155, loss = 0.13943927\n",
            "Iteration 156, loss = 0.13864583\n",
            "Iteration 157, loss = 0.13786501\n",
            "Iteration 158, loss = 0.13709655\n",
            "Iteration 159, loss = 0.13634021\n",
            "Iteration 160, loss = 0.13559573\n",
            "Iteration 161, loss = 0.13486287\n",
            "Iteration 162, loss = 0.13414141\n",
            "Iteration 163, loss = 0.13343110\n",
            "Iteration 164, loss = 0.13273174\n",
            "Iteration 165, loss = 0.13204311\n",
            "Iteration 166, loss = 0.13136499\n",
            "Iteration 167, loss = 0.13069717\n",
            "Iteration 168, loss = 0.13003947\n",
            "Iteration 169, loss = 0.12939168\n",
            "Iteration 170, loss = 0.12875361\n",
            "Iteration 171, loss = 0.12812508\n",
            "Iteration 172, loss = 0.12750591\n",
            "Iteration 173, loss = 0.12689591\n",
            "Iteration 174, loss = 0.12629492\n",
            "Iteration 175, loss = 0.12570276\n",
            "Iteration 176, loss = 0.12511927\n",
            "Iteration 177, loss = 0.12454430\n",
            "Iteration 178, loss = 0.12397767\n",
            "Iteration 179, loss = 0.12341924\n",
            "Iteration 180, loss = 0.12286887\n",
            "Iteration 181, loss = 0.12232639\n",
            "Iteration 182, loss = 0.12179166\n",
            "Iteration 183, loss = 0.12126456\n",
            "Iteration 184, loss = 0.12074493\n",
            "Iteration 185, loss = 0.12023264\n",
            "Iteration 186, loss = 0.11972757\n",
            "Iteration 187, loss = 0.11922958\n",
            "Iteration 188, loss = 0.11873854\n",
            "Iteration 189, loss = 0.11825434\n",
            "Iteration 190, loss = 0.11777685\n",
            "Iteration 191, loss = 0.11730595\n",
            "Iteration 192, loss = 0.11684154\n",
            "Iteration 193, loss = 0.11638348\n",
            "Iteration 194, loss = 0.11593168\n",
            "Iteration 195, loss = 0.11548602\n",
            "Iteration 196, loss = 0.11504640\n",
            "Iteration 197, loss = 0.11461272\n",
            "Iteration 198, loss = 0.11418486\n",
            "Iteration 199, loss = 0.11376273\n",
            "Iteration 200, loss = 0.11334624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP classifier has 4 activation function.They are\n",
        "\n",
        "1.   identity --> f(x)=x\n",
        "2.   logistic --> f(x) = 1 / (1 + exp(-x))\n",
        "3.   tanh     --> f(x)=tanh(x)\n",
        "4.   relu     --> f(x)=max(0,x)\n",
        "\n",
        "relu is a default one"
      ],
      "metadata": {
        "id": "rs-atJzNAblR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP classifier has 3 types of solver.They are\n",
        "\n",
        "1.   lbfgs\n",
        "2.   sgd\n",
        "3.   adam\n",
        "\n",
        "adam is usually used if dataset is larget.\n",
        "If dataset is smaller lbfgs is used"
      ],
      "metadata": {
        "id": "dXKzZrVEB0lV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wg6dEPuuBZ_J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}